{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"What is Hanfor? # Hanfor h elps an alyzing an d for malizing r equirements. If you have many requirements it gets difficult to check that all of them are, e.g., consistent. No human can manually check >1000 requirements for consistency -- so we do our best with reviews. Also in new projects, what we often see, is that it takes a long time before there is a high test coverage on the requirements -- as the number of requirements increases over the releases, and thus also the test specifications have to cover more and more requirements. However, many defects are found by experience-based testing -- but these technique is often used quite late, as the first priority is to get a reasonable requirement-based coverage. To tackle that problem, Hanfor provides a method that consists of 3 steps: The Requirements Formalization The Requirements Check (on the formalized requirements) The Test Generation (on the formalized requirements) Example Picture 1 To make it possible for a computer to check a set of requirements for quality criteria, as e.g. consistency, it has to \"understand\" the semantics of the requirements. This could be achieved by using formal languages to express the requirements. However, they are rarely understandable for humans, so we would get requirements that the computer understands - but nearly no stakeholder. In this method we use a simple pattern language. The requirements expressed in the pattern language look like English sentences. Everything you can express in this patterns is then translated in the background into logical formulas. You could also easily translate them into German, Chinese, or other languages. Grammar of the specification language # The grammar is the following: REQ ::= ID: SCOPE, PATTERN . SCOPE ::= Globally | Before EXPR | After EXPR | Between EXPR and EXPR | After EXPR until EXPR PATTERN ::= It is never the case that EXPR holds | It is always the case that EXPR holds | It is always the case that if EXPR holds, then EXPR holds as well | Transition to states in which EXPR holds occur at most twice | It is always the case that ORDER | It is always the case that REALTIME ORDER ::= | If EXPR holds, then EXPR previously held | If EXPR holds and is succeded by EXPR, then EXPR previously held | If EXPR holds, then EXPR previously held and was preceeded by EXPR | If EXPR holds, then EXPR eventually holds and is succeeded by EXPR | If EXPR holds and is succeeded by EXPR, then EXPR eventually holds after EXPR | If EXPR holds, then EXPR eventually holds and is succeeded by EXPR where EXPR does not hold between EXPR and EXPR | If EXPR holds, then EXPR toggles EXPR REALTIME ::= Once EXPR becomes satisfied, it holds for at least DURATION | Once EXPR becomes satisfied, it holds for less than DURATION | EXPR holds at least every DURATION | If EXPR holds, then EXPR holds after at most DURATION | If EXPR holds for at least DURATION, then EXPR holds afterwards for at least DURATION | If EXPR holds for at least DURATION, then EXPR holds afterwards | If EXPR holds, then EXPR holds after at most DURATION for at least DURATION | If EXPR holds, then EXPR holds for at least DURATION | If EXPR holds, then there is at least one execution sequence such that EXPR holds after at most DURATION | After EXPR holds for DURATION, then EXPR holds | If EXPR holds, then EXPR toggles EXPR at most DURATION later EXPR is an expression (e.g. vehicleSpeed<10 && Terminal15==ON ). Thus, in a first step the informal requirements are translated into requirements in the specification language shown above. This is done manually. In the background the tool translates the requirements in specification language then into logical formulas. Example Picture 2 Tool support # The tool to assist this step is called Hanfor.It looks a little bit like Doors. It takes as input a csv-Export from Doors, and then stores the requirements. There are two IDs, the Hanfor ID and the Doors ID, so that you can synchronize the two databases, and can easily identify changes. Example Picture 3 Clicking on a requirements you can then specify the requirement in the specification language as visible in the next screenshot. The tool provides both patterns and also a signal database, so that you have a auto-complete function when filling out the variables. Example Picture 4 Example Picture 5 The tool checks for the following correctness criteria: Consistency Vacuity rt-Consistency Example Req1: It is always the case that \"IRTest\" holds. Req2: It is never the case that \"IRTest\" holds. Inconsistency can be resolved by erasing requirements changing requirements Example Req1: It is always the case that if \"Signal-A\" holds then \"Signal-B\" holds after at most 10 ms. Req2: It is never the case that \"Signal-A\" holds. These requirements are consistent, but the precondition of Req1 is never true, i.e., Req1 is vacuously satisfied in this set of requirements. Vacuity can be resolved by erasing requirements, or changing requirements Example Erase Req2 or make it less restrictive Change Req2 to Req2': Before \"Startup\", it is never the case that \"Signal-A\" holds. Realtime-consistency (rt-consistency) # A set of requirements is rt-inconsistent, if there are conflicts between requirements that arise after a certain time. Example Req1: It is always the case that if \u201eIRTest\u201c holds, then \u201eIRLampsOn\u201c holds after at most 10 seconds Req2: It is always the case that if \u201eIRTest\u201c holds, then \u201eNOT(IRLampsOn)\u201c holds for at least 6 seconds. is consistent, but there are assignments with a conflict as shown in the following example. Example Picture 6 As IRTest gets valid in timepoint t=4, req1 requires, that in the time interval t=[4...14] IRLampsOn gets true as well. As IRTest is still valid in timepoint t=10, req2 requires, that IRLampsOn stays \"false\" until at least t=16. Thus, in t=14 we have a conflict - however the system reacts, one requirement will be violated. Resolve rt-inconsistency by erasing requirements, or changing requirements, or adding requirements Erase Req2, or make it less restrictive \u2013Req2\u2018: It is always the case that if IRTest holds and it did not hold in the last 10 s, then NOT(IRLampsOn) holds for at least 6 s. Or add Req3: Once IRTest appears, it holds for at most 3 seconds. Req4: Once IRTest disappears, it is absent for at least 10 seconds System test case generation # When having the requirements formalized in the specification language, it makes sense to also automatically generate test specifications out of them. There are several reasons to do so: Example Picture 7 Thus the algorithm has to: Automatically generate system tests only using requirements Generate small set of tests (test suite) Generate one test case per output variable Generate so many tests that every requirement is tested Generate tests that may not lead to false positives Ensure traceability to the requirements (i.e. indicate what requirements are tested by the test) The generated Test (case) consists of Sequence of inputs (Initial state of system, Inputs for steps 1...n) Expected outcome (oracle for step n) Link to the tested requirement Generate a feedback if there are untestable requirements Output: Set of untestable requirements (No seq. of Inputs deterministically causes the output) Example Picture 8 Requirements to be tested req1: Globally, it is always the case that if \u2018A\u2019 holds then \u2018H\u2019 holds after at most \u201810\u2019 time units. req2: Globally, it is always the case that if \u2018B\u2019 holds then \u2018I\u2019 holds after at most \u201810\u2019 time units. req3: Globally, it is always the case that if \u2018H AND I\u2019 holds then \u2018O\u2019 holds after at most \u201810\u2019 time units. Testing requires information about observability. Thus, we need to categorize the variables into Input, Output, and Hidden (i.e. internal variables): Inputs: A, B Outputs: O Hidden: H, I In the Test Generator Tool you can choose the following options: generate System Test (i.e. the tests only speak about system inputs and outputs, but no internal variables) generate System Integration Test (i.e., the tests speak about system input, system outputs and internal variables) output of the test generation tool Case SystemTest: TestGeneratorResult: Found Test for: [O] Test Vector: Set inputs: A := true, B := true Wait for at most 20 for: O == true, (req3) Case System Integration Test: ------| Test: req3 |----------------------- TestGeneratorResult: Found Test for: [O] Test Vector: Set inputs: A := true, B := true Wait for at most 10 for: H == true (req1) Wait for at most 10 for: I == true (req2) Wait for at most 20 for: O == true, (req3)","title":"What is Hanfor?"},{"location":"#what-is-hanfor","text":"Hanfor h elps an alyzing an d for malizing r equirements. If you have many requirements it gets difficult to check that all of them are, e.g., consistent. No human can manually check >1000 requirements for consistency -- so we do our best with reviews. Also in new projects, what we often see, is that it takes a long time before there is a high test coverage on the requirements -- as the number of requirements increases over the releases, and thus also the test specifications have to cover more and more requirements. However, many defects are found by experience-based testing -- but these technique is often used quite late, as the first priority is to get a reasonable requirement-based coverage. To tackle that problem, Hanfor provides a method that consists of 3 steps: The Requirements Formalization The Requirements Check (on the formalized requirements) The Test Generation (on the formalized requirements) Example Picture 1 To make it possible for a computer to check a set of requirements for quality criteria, as e.g. consistency, it has to \"understand\" the semantics of the requirements. This could be achieved by using formal languages to express the requirements. However, they are rarely understandable for humans, so we would get requirements that the computer understands - but nearly no stakeholder. In this method we use a simple pattern language. The requirements expressed in the pattern language look like English sentences. Everything you can express in this patterns is then translated in the background into logical formulas. You could also easily translate them into German, Chinese, or other languages.","title":"What is Hanfor?"},{"location":"#grammar-of-the-specification-language","text":"The grammar is the following: REQ ::= ID: SCOPE, PATTERN . SCOPE ::= Globally | Before EXPR | After EXPR | Between EXPR and EXPR | After EXPR until EXPR PATTERN ::= It is never the case that EXPR holds | It is always the case that EXPR holds | It is always the case that if EXPR holds, then EXPR holds as well | Transition to states in which EXPR holds occur at most twice | It is always the case that ORDER | It is always the case that REALTIME ORDER ::= | If EXPR holds, then EXPR previously held | If EXPR holds and is succeded by EXPR, then EXPR previously held | If EXPR holds, then EXPR previously held and was preceeded by EXPR | If EXPR holds, then EXPR eventually holds and is succeeded by EXPR | If EXPR holds and is succeeded by EXPR, then EXPR eventually holds after EXPR | If EXPR holds, then EXPR eventually holds and is succeeded by EXPR where EXPR does not hold between EXPR and EXPR | If EXPR holds, then EXPR toggles EXPR REALTIME ::= Once EXPR becomes satisfied, it holds for at least DURATION | Once EXPR becomes satisfied, it holds for less than DURATION | EXPR holds at least every DURATION | If EXPR holds, then EXPR holds after at most DURATION | If EXPR holds for at least DURATION, then EXPR holds afterwards for at least DURATION | If EXPR holds for at least DURATION, then EXPR holds afterwards | If EXPR holds, then EXPR holds after at most DURATION for at least DURATION | If EXPR holds, then EXPR holds for at least DURATION | If EXPR holds, then there is at least one execution sequence such that EXPR holds after at most DURATION | After EXPR holds for DURATION, then EXPR holds | If EXPR holds, then EXPR toggles EXPR at most DURATION later EXPR is an expression (e.g. vehicleSpeed<10 && Terminal15==ON ). Thus, in a first step the informal requirements are translated into requirements in the specification language shown above. This is done manually. In the background the tool translates the requirements in specification language then into logical formulas. Example Picture 2","title":"Grammar of the specification language"},{"location":"#tool-support","text":"The tool to assist this step is called Hanfor.It looks a little bit like Doors. It takes as input a csv-Export from Doors, and then stores the requirements. There are two IDs, the Hanfor ID and the Doors ID, so that you can synchronize the two databases, and can easily identify changes. Example Picture 3 Clicking on a requirements you can then specify the requirement in the specification language as visible in the next screenshot. The tool provides both patterns and also a signal database, so that you have a auto-complete function when filling out the variables. Example Picture 4 Example Picture 5 The tool checks for the following correctness criteria: Consistency Vacuity rt-Consistency Example Req1: It is always the case that \"IRTest\" holds. Req2: It is never the case that \"IRTest\" holds. Inconsistency can be resolved by erasing requirements changing requirements Example Req1: It is always the case that if \"Signal-A\" holds then \"Signal-B\" holds after at most 10 ms. Req2: It is never the case that \"Signal-A\" holds. These requirements are consistent, but the precondition of Req1 is never true, i.e., Req1 is vacuously satisfied in this set of requirements. Vacuity can be resolved by erasing requirements, or changing requirements Example Erase Req2 or make it less restrictive Change Req2 to Req2': Before \"Startup\", it is never the case that \"Signal-A\" holds.","title":"Tool support"},{"location":"#realtime-consistency-rt-consistency","text":"A set of requirements is rt-inconsistent, if there are conflicts between requirements that arise after a certain time. Example Req1: It is always the case that if \u201eIRTest\u201c holds, then \u201eIRLampsOn\u201c holds after at most 10 seconds Req2: It is always the case that if \u201eIRTest\u201c holds, then \u201eNOT(IRLampsOn)\u201c holds for at least 6 seconds. is consistent, but there are assignments with a conflict as shown in the following example. Example Picture 6 As IRTest gets valid in timepoint t=4, req1 requires, that in the time interval t=[4...14] IRLampsOn gets true as well. As IRTest is still valid in timepoint t=10, req2 requires, that IRLampsOn stays \"false\" until at least t=16. Thus, in t=14 we have a conflict - however the system reacts, one requirement will be violated. Resolve rt-inconsistency by erasing requirements, or changing requirements, or adding requirements Erase Req2, or make it less restrictive \u2013Req2\u2018: It is always the case that if IRTest holds and it did not hold in the last 10 s, then NOT(IRLampsOn) holds for at least 6 s. Or add Req3: Once IRTest appears, it holds for at most 3 seconds. Req4: Once IRTest disappears, it is absent for at least 10 seconds","title":"Realtime-consistency (rt-consistency)"},{"location":"#system-test-case-generation","text":"When having the requirements formalized in the specification language, it makes sense to also automatically generate test specifications out of them. There are several reasons to do so: Example Picture 7 Thus the algorithm has to: Automatically generate system tests only using requirements Generate small set of tests (test suite) Generate one test case per output variable Generate so many tests that every requirement is tested Generate tests that may not lead to false positives Ensure traceability to the requirements (i.e. indicate what requirements are tested by the test) The generated Test (case) consists of Sequence of inputs (Initial state of system, Inputs for steps 1...n) Expected outcome (oracle for step n) Link to the tested requirement Generate a feedback if there are untestable requirements Output: Set of untestable requirements (No seq. of Inputs deterministically causes the output) Example Picture 8 Requirements to be tested req1: Globally, it is always the case that if \u2018A\u2019 holds then \u2018H\u2019 holds after at most \u201810\u2019 time units. req2: Globally, it is always the case that if \u2018B\u2019 holds then \u2018I\u2019 holds after at most \u201810\u2019 time units. req3: Globally, it is always the case that if \u2018H AND I\u2019 holds then \u2018O\u2019 holds after at most \u201810\u2019 time units. Testing requires information about observability. Thus, we need to categorize the variables into Input, Output, and Hidden (i.e. internal variables): Inputs: A, B Outputs: O Hidden: H, I In the Test Generator Tool you can choose the following options: generate System Test (i.e. the tests only speak about system inputs and outputs, but no internal variables) generate System Integration Test (i.e., the tests speak about system input, system outputs and internal variables) output of the test generation tool Case SystemTest: TestGeneratorResult: Found Test for: [O] Test Vector: Set inputs: A := true, B := true Wait for at most 20 for: O == true, (req3) Case System Integration Test: ------| Test: req3 |----------------------- TestGeneratorResult: Found Test for: [O] Test Vector: Set inputs: A := true, B := true Wait for at most 10 for: H == true (req1) Wait for at most 10 for: I == true (req2) Wait for at most 20 for: O == true, (req3)","title":"System test case generation"},{"location":"contribute/to_docs/","text":"These are the source files for the Hanfor Documentation . Contribute to this Documentation. # Install MkDocs and all dependencies. $ pip install mkdocs pymdown-extensions $ pip install -e git+https://github.com/jdittrich/figureAltCaption#egg=figureAltCaption $ pip install -e git+https://github.com/MrLeeh/markdown-lightbox.git#egg=markdown-lightbox Serve this Documentation locally to track your changes. $ cd to_here $ mkdocs serve Open your Browser at http://127.0.0.1:8000/ . Publish your changes to the staging directory. $ mkdocs gh-deploy --remote-branch gh-pages-staging This will build the Documentation and commit them to the gh-pages-staging branch and push the gh-pages-staging branch to GitHub. If you have the necessary rights, you can then see the results on https://struebli.informatik.uni-freiburg.de/hanfor-docs-staging. Publish your changes to the live directory ory. $ mkdocs gh-deploy This will build the Documentation and commit them to the gh-pages branch and push the gh-pages branch to GitHub. They will then be immediately available to the world at https://ultimate-pa.github.io/hanfor.","title":"To Docs"},{"location":"contribute/to_docs/#contribute-to-this-documentation","text":"Install MkDocs and all dependencies. $ pip install mkdocs pymdown-extensions $ pip install -e git+https://github.com/jdittrich/figureAltCaption#egg=figureAltCaption $ pip install -e git+https://github.com/MrLeeh/markdown-lightbox.git#egg=markdown-lightbox Serve this Documentation locally to track your changes. $ cd to_here $ mkdocs serve Open your Browser at http://127.0.0.1:8000/ . Publish your changes to the staging directory. $ mkdocs gh-deploy --remote-branch gh-pages-staging This will build the Documentation and commit them to the gh-pages-staging branch and push the gh-pages-staging branch to GitHub. If you have the necessary rights, you can then see the results on https://struebli.informatik.uni-freiburg.de/hanfor-docs-staging. Publish your changes to the live directory ory. $ mkdocs gh-deploy This will build the Documentation and commit them to the gh-pages branch and push the gh-pages branch to GitHub. They will then be immediately available to the world at https://ultimate-pa.github.io/hanfor.","title":"Contribute to this Documentation."},{"location":"contribute/to_hanfor/","text":"Hanfor # You know the drill, head over to Hanfor's Git repository and fork it, then work in your changes and PR.","title":"To Hanfor"},{"location":"contribute/to_hanfor/#hanfor","text":"You know the drill, head over to Hanfor's Git repository and fork it, then work in your changes and PR.","title":"Hanfor"},{"location":"installation/configuration/","text":"Configuration # Hanfor # Copy ./hanfor/config.dist.py to ./hanfor/config.py . Edit the file /hanfor/config.py according your needs. Hanfor config file: # A config file looks as follows: ################################################################################ # Storage and folders # ################################################################################ # Set the SESSION_BASE_FOLDER to a path hanfor will store/load sessions. # If set to None, hanfor will store its sessions in ./data SESSION_BASE_FOLDER = './data' ################################################################################ # DEBUG and logging # ################################################################################ # Set DEBUG_MODE to true if you want to run the flask app in debug mode. # In Production this should be set to False. DEBUG_MODE = False # If ASSETS_DEBUG True, Bundles will output their individual source files. # This will significantly slow down performance. ASSETS_DEBUG = False # Set this to false if you want to use DEBUG toolbar with a URL_PREFIX DEBUG_TB_INTERCEPT_REDIRECTS = False # Set the log level to increase or decrease the logging sensitivity. # You can set LOG_LEVEL (in decreasing sensitivity to): # 'DEBUG', 'INFO', 'WARNING', 'ERROR' LOG_LEVEL = 'DEBUG' # Set LOG_TO_FILE to True if vou want to log to the file # you specified in LOG_FILE LOG_TO_FILE = True LOG_FILE = 'hanfor.log' # Set PYCHARM_DEBUG to True to supresss the flask debugging so it # won't interfere with the pycharm debugger. PYCHARM_DEBUG = False ################################################################################ # App and web server section # ################################################################################ # If you are running the app with a url prefix set URL_PREFIX like # URL_PREFIX = '/hanfor' URL_PREFIX = '' # set a 'SECRET_KEY' to enable the Flask session cookies SECRET_KEY = 'somesecretkeythatisonlyknowntoyou' # Specify the PORT the app should be running at PORT = 5000 # Set the host HOST = '127.0.0.1' ReqAnalyzer # Coming soon","title":"Configuration"},{"location":"installation/configuration/#configuration","text":"","title":"Configuration"},{"location":"installation/configuration/#hanfor","text":"Copy ./hanfor/config.dist.py to ./hanfor/config.py . Edit the file /hanfor/config.py according your needs.","title":"Hanfor"},{"location":"installation/configuration/#hanfor-config-file","text":"A config file looks as follows: ################################################################################ # Storage and folders # ################################################################################ # Set the SESSION_BASE_FOLDER to a path hanfor will store/load sessions. # If set to None, hanfor will store its sessions in ./data SESSION_BASE_FOLDER = './data' ################################################################################ # DEBUG and logging # ################################################################################ # Set DEBUG_MODE to true if you want to run the flask app in debug mode. # In Production this should be set to False. DEBUG_MODE = False # If ASSETS_DEBUG True, Bundles will output their individual source files. # This will significantly slow down performance. ASSETS_DEBUG = False # Set this to false if you want to use DEBUG toolbar with a URL_PREFIX DEBUG_TB_INTERCEPT_REDIRECTS = False # Set the log level to increase or decrease the logging sensitivity. # You can set LOG_LEVEL (in decreasing sensitivity to): # 'DEBUG', 'INFO', 'WARNING', 'ERROR' LOG_LEVEL = 'DEBUG' # Set LOG_TO_FILE to True if vou want to log to the file # you specified in LOG_FILE LOG_TO_FILE = True LOG_FILE = 'hanfor.log' # Set PYCHARM_DEBUG to True to supresss the flask debugging so it # won't interfere with the pycharm debugger. PYCHARM_DEBUG = False ################################################################################ # App and web server section # ################################################################################ # If you are running the app with a url prefix set URL_PREFIX like # URL_PREFIX = '/hanfor' URL_PREFIX = '' # set a 'SECRET_KEY' to enable the Flask session cookies SECRET_KEY = 'somesecretkeythatisonlyknowntoyou' # Specify the PORT the app should be running at PORT = 5000 # Set the host HOST = '127.0.0.1'","title":"Hanfor config file:"},{"location":"installation/configuration/#reqanalyzer","text":"Coming soon","title":"ReqAnalyzer"},{"location":"installation/deployment/","text":"Deployment # To start a fresh session use $ python app.py <tag> -c <path_to_input_csv>.csv Point your browser to http://127.0.0.1:<port in config.py> If you want to start an existing session, use $ python app.py <tag> You can see all available tags using the ''-L'' switch: $ python app.py -L How it works # The app will create a session naming it by the given <tag> argument. A session creation process has the following steps: Create a session in a folder config.py_SESSION_BASE_FOLDER/<tag> . Read the given .csv file containing one requirement each row. Ask the user about a mapping of the csv-header-names for: \"ID\", \"Description\", \"Formalized Requirement\", \"Type\" Create a Hanfor-Requirement for each row in the csv and store it to the session folder. Provide the Web-interface on the port specified in config.py","title":"Deployment"},{"location":"installation/deployment/#deployment","text":"To start a fresh session use $ python app.py <tag> -c <path_to_input_csv>.csv Point your browser to http://127.0.0.1:<port in config.py> If you want to start an existing session, use $ python app.py <tag> You can see all available tags using the ''-L'' switch: $ python app.py -L","title":"Deployment"},{"location":"installation/deployment/#how-it-works","text":"The app will create a session naming it by the given <tag> argument. A session creation process has the following steps: Create a session in a folder config.py_SESSION_BASE_FOLDER/<tag> . Read the given .csv file containing one requirement each row. Ask the user about a mapping of the csv-header-names for: \"ID\", \"Description\", \"Formalized Requirement\", \"Type\" Create a Hanfor-Requirement for each row in the csv and store it to the session folder. Provide the Web-interface on the port specified in config.py","title":"How it works"},{"location":"installation/preliminaries/","text":"Preliminaries # Install Hanfor # Clone the repository: $ git clone https://github.com/ultimate-pa/hanfor.git -b master --single-branch /your/hanfor/destination Hanfor requires Python and is only tested with Python 3.6.x. You can check if you have python already installed from the command line: $ python -- version Python 3.6.2 We recommend using a virtual environment . Create a new virtual environment with: $ virtualenv hanfor_python And activate it by sourcing: $ source hanfor_python/bin/activate Now the python dependencies needed to be installed into the virtual environment. Inside the repository run: $ pip install -r requirements.txt Install ReqAnalyzer # Coming soon","title":"Preliminaries"},{"location":"installation/preliminaries/#preliminaries","text":"","title":"Preliminaries"},{"location":"installation/preliminaries/#install-hanfor","text":"Clone the repository: $ git clone https://github.com/ultimate-pa/hanfor.git -b master --single-branch /your/hanfor/destination Hanfor requires Python and is only tested with Python 3.6.x. You can check if you have python already installed from the command line: $ python -- version Python 3.6.2 We recommend using a virtual environment . Create a new virtual environment with: $ virtualenv hanfor_python And activate it by sourcing: $ source hanfor_python/bin/activate Now the python dependencies needed to be installed into the virtual environment. Inside the repository run: $ pip install -r requirements.txt","title":"Install Hanfor"},{"location":"installation/preliminaries/#install-reqanalyzer","text":"Coming soon","title":"Install ReqAnalyzer"},{"location":"usage/api_queries/","text":"API queries # To generate reports or search for requirements not using the frontend Hanfor can be queried with HTTP requests at http(s)://{{your host}}/{{your URL_PREFIX}}/api/query Show stored queries # GET /api/query URL arguments # Name Type Description name string Name of the Query to retrieve a single Query. reload bool, optional Reevaluates all stored Queries. Examples # # Show all stored Queries $ curl http://localhost:5000/api/query # Show only Queries which are named 'MyQuery' and re-evaluate the stored Query $ curl http://localhost:5000/api/query?name=MyQuery&reload=true # Using jq to parse the JSON response. Show only the name of the query with associated hits. $ curl http://localhost:5000/api/query\\?reload\\=true | jq -r '.data[] | {name: .name, hits: .hits}' Adding new queries # POST /api/query Content-Type: application/json JSON body parameters # Name Type Description name string Name for the Query. Existing ones will be overridden. query string The search Query. Examples # $ curl -X POST -H 'Content-Type: application/json' \\ --data '{\"name\": \"MyQuery\", \"query\": \"foo:AND:bar\"}' http://localhost:5000/api/query Deleting queries # DELETE /api/query JSON body parameters # Name Type Description name string Name for the Query to be deleted. names list of strings Queries by name to be deleted. Examples # # Delete a single Query: $ curl -X DELETE -H 'Content-Type: application/json' \\ --data '{\"name\": \"MyQuery\"}' http://localhost:5000/api/query # Delete multiple Queries: $ curl -X DELETE -H 'Content-Type: application/json' \\ --data '{\"names\": [\"MyQuery\", \"Another\"]' http://localhost:5000/api/query Query syntax # Much like in the frontend the Query syntax supports operators, nesting, exact- exclusive matches and targeting specific attributes. Search operators # You can concatenate search Queries by search_1:OR:search_2 yields the union of search_1 and search_2. search_1:AND:search_2 yields the intersection of search_1 and search_2. :AND: binds stronger than :OR: . To invert the result use :NOT: before your search string. To change the precedence or to nest a Query ( and ) . Exact searches # You can get exact search results by using \" to indicate the beginning or end of a sequence. \"fast Includes faster but not breakfast. fast\" Includes breakfast but not faster. \"fast\" Includes only exact matches of fast. Target specific attributes # To limit a part of the search Query to one attribute use the syntax :DATA_TARGET:<the attribute name> Note: the attribute name must be enclosed with backticks. Get available attributes # GET /api/quer?show=targets Example # # Show attribute names available for specific search. $ curl http://localhost:5000/api/query?show=targets Default targets: The available targets are composed of [ \"Description\", \"Formalization\", \"Id\", \"Status\", \"Tags\", \"Type\" ] Plus the fields available in the associated CSV file the requirements origin from.","title":"API Queries"},{"location":"usage/api_queries/#api-queries","text":"To generate reports or search for requirements not using the frontend Hanfor can be queried with HTTP requests at http(s)://{{your host}}/{{your URL_PREFIX}}/api/query","title":"API queries"},{"location":"usage/api_queries/#show-stored-queries","text":"GET /api/query","title":"Show stored queries"},{"location":"usage/api_queries/#url-arguments","text":"Name Type Description name string Name of the Query to retrieve a single Query. reload bool, optional Reevaluates all stored Queries.","title":"URL arguments"},{"location":"usage/api_queries/#examples","text":"# Show all stored Queries $ curl http://localhost:5000/api/query # Show only Queries which are named 'MyQuery' and re-evaluate the stored Query $ curl http://localhost:5000/api/query?name=MyQuery&reload=true # Using jq to parse the JSON response. Show only the name of the query with associated hits. $ curl http://localhost:5000/api/query\\?reload\\=true | jq -r '.data[] | {name: .name, hits: .hits}'","title":"Examples"},{"location":"usage/api_queries/#adding-new-queries","text":"POST /api/query Content-Type: application/json","title":"Adding new queries"},{"location":"usage/api_queries/#json-body-parameters","text":"Name Type Description name string Name for the Query. Existing ones will be overridden. query string The search Query.","title":"JSON body parameters"},{"location":"usage/api_queries/#examples_1","text":"$ curl -X POST -H 'Content-Type: application/json' \\ --data '{\"name\": \"MyQuery\", \"query\": \"foo:AND:bar\"}' http://localhost:5000/api/query","title":"Examples"},{"location":"usage/api_queries/#deleting-queries","text":"DELETE /api/query","title":"Deleting queries"},{"location":"usage/api_queries/#json-body-parameters_1","text":"Name Type Description name string Name for the Query to be deleted. names list of strings Queries by name to be deleted.","title":"JSON body parameters"},{"location":"usage/api_queries/#examples_2","text":"# Delete a single Query: $ curl -X DELETE -H 'Content-Type: application/json' \\ --data '{\"name\": \"MyQuery\"}' http://localhost:5000/api/query # Delete multiple Queries: $ curl -X DELETE -H 'Content-Type: application/json' \\ --data '{\"names\": [\"MyQuery\", \"Another\"]' http://localhost:5000/api/query","title":"Examples"},{"location":"usage/api_queries/#query-syntax","text":"Much like in the frontend the Query syntax supports operators, nesting, exact- exclusive matches and targeting specific attributes.","title":"Query syntax"},{"location":"usage/api_queries/#search-operators","text":"You can concatenate search Queries by search_1:OR:search_2 yields the union of search_1 and search_2. search_1:AND:search_2 yields the intersection of search_1 and search_2. :AND: binds stronger than :OR: . To invert the result use :NOT: before your search string. To change the precedence or to nest a Query ( and ) .","title":"Search operators"},{"location":"usage/api_queries/#exact-searches","text":"You can get exact search results by using \" to indicate the beginning or end of a sequence. \"fast Includes faster but not breakfast. fast\" Includes breakfast but not faster. \"fast\" Includes only exact matches of fast.","title":"Exact searches"},{"location":"usage/api_queries/#target-specific-attributes","text":"To limit a part of the search Query to one attribute use the syntax :DATA_TARGET:<the attribute name> Note: the attribute name must be enclosed with backticks.","title":"Target specific attributes"},{"location":"usage/api_queries/#get-available-attributes","text":"GET /api/quer?show=targets","title":"Get available attributes"},{"location":"usage/api_queries/#example","text":"# Show attribute names available for specific search. $ curl http://localhost:5000/api/query?show=targets Default targets: The available targets are composed of [ \"Description\", \"Formalization\", \"Id\", \"Status\", \"Tags\", \"Type\" ] Plus the fields available in the associated CSV file the requirements origin from.","title":"Example"},{"location":"usage/faq/","text":"FAQ # Change description or a field text in requirements table. # Currently there is only one way to achieve this: \u201cCreating a new revision\u201d: Edit the Description in the CSV -> edited.csv . Create a revision with the edited CSV as baseline: python app.py TAG_NAME -c path/to/edited.csv --revision This will check for changes in the CSV against the old one and create a new \u201cVersion\u201d aka. \u201cRevision\u201d.","title":"FAQ"},{"location":"usage/faq/#faq","text":"","title":"FAQ"},{"location":"usage/faq/#change-description-or-a-field-text-in-requirements-table","text":"Currently there is only one way to achieve this: \u201cCreating a new revision\u201d: Edit the Description in the CSV -> edited.csv . Create a revision with the edited CSV as baseline: python app.py TAG_NAME -c path/to/edited.csv --revision This will check for changes in the CSV against the old one and create a new \u201cVersion\u201d aka. \u201cRevision\u201d.","title":"Change description or a field text in requirements table."},{"location":"usage/requirements/","text":"Requirements # Search in requirements table # Searching in the requirements table is accessible via the search tab. Typing in the search input supports autocomplete for extended search triggered by : . Search Operators # You can concatenate search queries by search_1:OR:search_2 yields the union of search_1 and search_2. search_1:AND:search_2 yields the intersection of search_1 and search_2. :AND: binds stronger than :OR: . To invert the result use :NOT: before your search string. Exact searches # You can get exact search results by using \" to indicate the beginning or end of a sequence. \"fast Includes faster but not breakfast. fast\" Includes breakfast but not faster. \"fast\" Includes only exact matches of fast. Search Target column To target a specific column use :COL_INDEX_02: to target column 2. The column indexes are appended in the requirements table header in parentheses. Mass edit requirements # You can mass edit requirements. Select requirements by clicking on the requirement checkbox in the table. Hold shift for multi select and Ctrl to toggle a single selection. Click on Edit Selected , fill out the form. Empty fields will have no effect.","title":"Requirements"},{"location":"usage/requirements/#requirements","text":"","title":"Requirements"},{"location":"usage/requirements/#search-in-requirements-table","text":"Searching in the requirements table is accessible via the search tab. Typing in the search input supports autocomplete for extended search triggered by : .","title":"Search in requirements table"},{"location":"usage/requirements/#search-operators","text":"You can concatenate search queries by search_1:OR:search_2 yields the union of search_1 and search_2. search_1:AND:search_2 yields the intersection of search_1 and search_2. :AND: binds stronger than :OR: . To invert the result use :NOT: before your search string.","title":"Search Operators"},{"location":"usage/requirements/#exact-searches","text":"You can get exact search results by using \" to indicate the beginning or end of a sequence. \"fast Includes faster but not breakfast. fast\" Includes breakfast but not faster. \"fast\" Includes only exact matches of fast.","title":"Exact searches"},{"location":"usage/requirements/#mass-edit-requirements","text":"You can mass edit requirements. Select requirements by clicking on the requirement checkbox in the table. Hold shift for multi select and Ctrl to toggle a single selection. Click on Edit Selected , fill out the form. Empty fields will have no effect.","title":"Mass edit requirements"},{"location":"usage/workflow/","text":"Workflow # This example and everything that belongs to it is located in hanfor/example . Example input # Consider a CSV file example_input.csv which contains requirements: ID,Description,Type META1,This is an example for some requirements,meta META2,Next we define some requirements,meta REQ1,var1 is always greater than 5,requirement REQ2,var2 is always smaller than 10,requirement REQ3,constraint1 always holds,requirement REQ4,constraint2 always holds,requirement REQ5,var1 is always smaller than 5,requirement REQ6,constraint1 and constraint2 never hold at the same time,requirement REQ7,if var1 = True then var3 := 1,requirement REQ8,if var1 = True then var3 := 0,requirement In this case every row consists of the fields ID , Description , Formalized Requirement and Type . ID is a unique identifier, Description is the description , Formalized Requirement , is the formalization, Type , is a type, in this example meta or requirement , where rows with type meta contain some meta-information and rows with type requirement contain actual requirements of the module you want to formalize. Fire up Hanfor # Configure Hanfor as explained in Configuration Start Hanfor: cd hanfor python3 app.py -c example_input.csv example_tag -c example_input.csv specifies the csv input file we pass. example_tag is some meaningful tag you want to give this session. If you start hanfor later with the same tag, you'll start exactly this session. you can now reach Hanfor by visiting http://127.0.0.1:5000 Hanfor requirement overview Preprocessing # By default, all rows now have the status Todo . It might be the case that you want to change this for a certain set of rows to another status. In this example we want to set every row of type meta to the status Done . To accomplish this we use the Search Query Language . In Hanfor, search :COL_INDEX_04:meta . This will search for rows which match \"meta\" in the 4. coloumn (Type). You should now only see the rows of type meta . Select all rows by clicking All . Click Edit selected and select Done in the field Set status . Finally, click Apply changes to selected requirements Formalization # Order your requirement overview by Pos by clicking on the table column. REQ1 # To formalize this requirement, we click on the ID REQ1 to open then formalization-modal: Formalization modal Click on + to add a new formalization and then on ..(click to open) We now have to select a Scope and a Pattern . - The scope is Globally , because the requirement states that \"var1 is always greater than 5\". - The pattern is it is always the case that {R} holds . - For {R} we insert the condition: var1 > 5 - Set the status to Review and then press save changes . If you save a requirement, Hanfor will automatically create the used variables and derive their type. You can examine and even alter them in the section Variables , for the case that Hanfor did not derive a variable-type correctly. Definition of Scope and Pattern The same procedure can be applied to REQ2 - REQ6 REQ7 and REQ8 # REQ7 and REQ8 are different. Consider REQ7: if var3 = True then var4 := True . The scope is still Globally The pattern is it is always the case that if \"{R}\" holds, then \"{S}\" holds after at most \"{T}\" time units , because in a realtime-system a variable assignment does not happen instantly, there can be delays. For {R} we insert var3 , because the variable type is boolean. For {S} insert var4 , For {T} we need a certain amount of time units, for example 50. We do not want to hardcode values, we introduce a new variable and insert MAX_TIME . We end up with the following: Globally, it is always the case that if \"var3\" holds, then \"var4\" holds after at most \"MAX_TIME\" time units. Save the formalization. You will now recognize that Hanfor automatically added a new Tag Type_inference_error to your freshly formalized requirement. To fix that, to go the Variables section and open the MAX_TIME variable. You see that Hanfor derived the type bool , but we actually want it to be of type CONST as the variable represents time units. Change the type and also assign a value, for example 50 . Example for the MAX_TIME variable For REQ8 you should have: Globally, it is always the case that if \"var3\" holds, then \"!var4\" holds after at most \"MAX_TIME\" time units. Exporting the formalized requirements. # Once you are done with all requirements, it is time to analyze them using a tool like Ultimate (TODO:ref to git). Preparing the export. # You might want to filter out some rows, for example, all of type meta or all that have a certain tag. Again, use the Search Query Language to select only the requirements you want. For example, if we only rows of type requirement which are not on status Todo we search: :COL_INDEX_04:requirement:AND::COL_INDEX_06::NOT:Todo Export # To export requirements, press Tools , then choose either .req or .csv . If you want to analyze the requirements using Ultimate, choose Generate .req file from (filtered) requirements table and then save it. You should end up with the following: CONST MAX_TIME IS 50.0 Input constraint1 IS bool Input constraint2 IS bool Input var1 IS int Input var2 IS int Input var3 IS bool Input var4 IS bool REQ1_0: Globally, it is always the case that \"var1 > 5\" holds REQ2_0: Globally, it is always the case that \"var2 < 10\" holds REQ3_0: Globally, it is always the case that \"constraint1\" holds REQ4_0: Globally, it is always the case that \"constraint2\" holds REQ5_0: Globally, it is always the case that \"var1 < 5\" holds REQ6_0: Globally, it is never the case that \"constraint1 && constraint2 \" holds REQ7_0: Globally, it is always the case that if \"var3\" holds, then \"var4\" holds after at most \"MAX_TIME\" time units REQ8_0: Globally, it is always the case that if \"var3\" holds, then \"!var4\" holds after at most \"MAX_TIME \" time units Analysis using Ultimate. # Get Ultimate # First of all you need Ultimate Install Java JDK (1.8) and Maven (>3.0) Clone the repository: git clone https://github.com/ultimate-pa/ultimate . Navigate to the release scripts cd ultimate/releaseScripts/default/ Generate a fresh binary ./makeFresh.sh You have now successfully forged binaries, which are located in UAutomizer-linux/ . Scripts to perform the complete analysis. # We wrote scripts, which perform a complete anaylsis, including the extraction of relevant stuff. Just copy the following three scripts, and change the directories in the head of the files where it is necessary. explode_script.py : #!/usr/bin/env python3 import argparse import re import sys def get_top_operands(s): operands = [] pstack = [] last_space = None for i, c in enumerate(s): if c == '(': pstack.append(i) elif c == ')': if len(pstack) == 0: print(s) raise IndexError(\"No matching closing parens at: \" + str(i)) j = pstack.pop() last_space = None if len(pstack) == 0: operands.append(s[j:i + 1]) elif c == ' ': if not last_space: last_space = i else: if len(pstack) == 0: # we have a top level operand without parenthesis operands.append(s[last_space:i + 1]) last_space = i if len(pstack) > 0: print(s) raise IndexError(\"No matching opening parens at: \" + str(pstack.pop())) return operands def split_and(s): if s.startswith('(and'): rtr = [] for operand in get_top_operands(s[5:len(s) - 1]): rtr = rtr + split_and(operand) return rtr else: return [s] parser = argparse.ArgumentParser(description='Convert (assert (and o1 o2 ...)) to (assert o1) (assert o2) (assert ...)') parser.add_argument('-i', '--input', nargs=1, metavar='<file>', required=True, help='Specify input file') parser.add_argument('-o', '--output', nargs=1, metavar='<file>', required=True, help='Specify output file') try: args, extras = parser.parse_known_args() except argparse.ArgumentError as exc: print(exc.message + '\\n' + exc.argument) sys.exit(1) input_script = args.input[0] output_script = args.output[0] if input_script == output_script: print('Input and output file must be different') sys.exit(1) try: with open(input_script, encoding='utf-8') as f, open(output_script, 'w', encoding='utf-8') as o: for line in f.readlines(): if line.startswith(\"(assert (!\"): m = re.search('\\(assert \\(! (.*?) :named (.*?)\\)\\)', line) formula = m.group(1) if formula == 'true': continue name = m.group(2) asserts = split_and(formula) if len(asserts) == 1: o.write('(assert (! {} :named {}))\\n'.format(asserts[0], name)) else: i = 0 for sub in asserts: o.write('(assert (! {} :named {}))\\n'.format(sub, name + '_' + str(i))) i = i + 1 else: o.write(line) except FileNotFoundError as exc: print('Did not find ' + input_script) print('Arguments were '+ str(args)) sys.exit(1) extract_vac_reasons.sh , used to extract reasons why a requirement is vacuous. #!/bin/bash # script that prepares a .req file with the reasons for vacuity for a known vacuous requirement # start it from the initial dump directory orig_req_file=\"${1}\" ultimate_log=\"${2}\" # This is what you have to change: requirement_repo=\"/storage/repos/your_requirement_repo\" ultimate_repo=\"/storage/repos/ultimate\" explode=\"${requirement_repo}/explode_script.py\" ultimate_dir=\"${ultimate_repo}/releaseScripts/default/UAutomizer-linux\" # Below here you do not have to change anything, except you know what you are doing. tmp_dump_dir=\"dump-ss\" dump_dir=\"dump\" function check_params(){ if [[ $PWD != *\"$dump_dir\" ]]; then echo \"Not in directory $dump_dir\" exit 1; fi } function parse_results(){ mapfile -t results < <( grep -oP ' - .*Result.*' \"$ultimate_log\" | grep 'is vacuous' | grep -oP 'Requirement .* is' | cut -d ' ' -f 2 ) } function print_results(){ if [ ${#results[@]} -eq 0 ]; then echo \"No vacuous requirements remaining! This is unexpected. Check $reduced_req_file and $ultimate_log\" return 1 else echo \"${#results[@]} requirements still vacuous: ${results[@]}\" return 0 fi } function get_involved_reqs(){ local reason_file=\"$req_id.vac\" local tmp_file=\"$req_id.tmp\" local regexpr=\"\" if readlink -e \"$tmp_file\" > /dev/null ; then echo \"$tmp_file still exists\" exit 1 fi for smt_file in $smt_file_pref do echo \"Considering $smt_file\" tmp_smt_file=\"${smt_file}.lbe\" eval \"$explode -i $smt_file -o $tmp_smt_file\" if ! readlink -e \"$tmp_smt_file\" > /dev/null ; then echo \"$explode -i $smt_file -o $tmp_smt_file did not produce the expected output, something is wrong\" echo \"The current folder is $PWD\" exit 1 fi sed -i 's/(get-interpolants.*/(get-unsat-core)/g' \"$tmp_smt_file\" sed -i '/\\:interpolant-check-mode/d' \"$tmp_smt_file\" sed -i '/\\:proof-transformation/d' \"$tmp_smt_file\" sed -i '/\\:array-interpolation/d' \"$tmp_smt_file\" # You can check if z3 complains about something in the file #../z3 \"$tmp_smt_file\" for i in `\"$ultimate_dir/z3\" \"$tmp_smt_file\" | grep -A 1 -P ^unsat$ | tail -n +2 | sed 's/(//g' | sed 's/)//g'`; do grep \"$i\" \"$tmp_smt_file\"; done | grep -oP 'SysRS_\\w+_\\d+_\\d+' | sort | uniq >> \"$tmp_file\" rm \"$tmp_smt_file\" done sort \"$tmp_file\" | uniq > \"$reason_file\" rm \"$tmp_file\" if ! grep -q \"$req_id\" \"$reason_file\" ; then echo \"TODO: if the tmp_file does not contain the req_id in the unsat core, we need to remove reasons for infeasibility and try again\" return 1 fi echo \"Found `wc -l $reason_file | cut -d \" \" -f 1` involved reqs\" tr '[:space:]' ' ' < \"$reason_file\" echo \"\" for i in `cat $reason_file` ; do regexpr+=\"\\|$i.*$\"; done rm \"$reason_file\" sed \"/CONST.*$\\|Input.*$\"\"$regexpr/!d\" \"$orig_req_file\" > \"$reduced_req_file\" return 0 } function run_ultimate_ss(){ rm -r \"$tmp_dump_dir\" mkdir \"$tmp_dump_dir\" ultimate_log=`readlink -f \"${tmp_dump_dir}/ultimate.log\"` echo \"Running Ultimate\" java -Dosgi.configuration.area=config/ \\ -Xmx10G \\ -jar plugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar \\ -tc \"${ultimate_repo}/trunk/examples/toolchains/ReqCheck.xml\" \\ -s \"${requirement_repo}/reqanalyzer-nonlin.epf\" \\ -i \"${dump_dir}/$reduced_req_file\" \\ --pea2boogie.check.consistency false \\ --pea2boogie.check.rt-inconsistency false \\ --traceabstraction.dump.smt.script.to.file true \\ --traceabstraction.to.the.following.directory=\"${tmp_dump_dir}/\" \\ > \"$ultimate_log\" } check_params parse_results initial_results=\"${results[@]}\" echo \"Processing ${#results[@]} vacuous requirements\" for i in ${initial_results[@]} do req_id=\"$i\" reduced_req_file=\"$req_id.vac.req\" echo \"----\" echo \"Processing $req_id\" smt_file_pref=\"*VAC*_\"`echo \"$req_id\" | cut -d \"_\" -f 3-`\"_*.smt2\" if ! get_involved_reqs ; then continue fi pushd \"$ultimate_dir\" > /dev/null run_ultimate_ss parse_results if print_results ; then pushd \"$tmp_dump_dir\" > /dev/null get_involved_reqs echo \"Writing $reduced_req_file\" cp \"$reduced_req_file\" \"../${dump_dir}/\" cp \"$reduced_req_file\" \"../\" popd > /dev/null fi popd > /dev/null echo \"Finished $req_id\" echo \"\" done run_complete_analysis.sh , used to run the complete analysis. #!/bin/bash # script that runs all the various requirement analysis scripts and moves files around in the matching directories ### Default settings # The requirement file is an argument passed to this script. req_file=\"$1\" # This is the path to the repository, which contains the requirements-folder req_repo_folder=\"/path/to/req/repo\" # This is the path to the requirements-folder req_folder=\"${req_repo_folder}/reqs\" # Path to the vacuity extractor script. vac_extractor=\"${req_repo_folder}/extract_vac_reasons.sh\" # Path to the Ultimate repository. ultimate_repo_folder=\"/storage/repos/ultimate\" # Path to Ultimate Automizer (remember those binaries we created earlier? that's what you want!). automizer_folder=\"${ultimate_repo_folder}/releaseScripts/default/UAutomizer-linux\" # Don't touch this, unless you know what you are doing. reqcheck_toolchain=\"${ultimate_repo_folder}/trunk/examples/toolchains/ReqCheck.xml\" reqcheck_settings=\"${ultimate_repo_folder}/trunk/examples/settings/reqanalyzer/reqanalyzer-nonlin.epf\" testgen_toolchain=\"${ultimate_repo_folder}/trunk/examples/toolchains/ReqToTest.xml\" testgen_settings=\"${ultimate_repo_folder}/trunk/examples/settings/ReqToTest.epf\" # The time how long a single assertion is checked. timeout_per_assertion=900 # The amount of requirements which are checked together for RT-inconsistency. # Careful with this parameter, it will blow up the amount of checks really fast. rt_inconsistency_range=2 ### Functions function prompt { read -p \"${1} [y/N]\" -n 1 -r echo \"\" if [[ $REPLY =~ ^[Yy]$ ]] ; then return 0 fi return 1 } function test_if_cmd_is_available { local cmd_path=`command -v \"$@\"` [ $? -eq 0 ] || { echo >&2 \"I require $@ but it's not installed. Aborting.\"; exit 1; } if ! [[ -f \"$cmd_path\" && -x $(realpath \"$cmd_path\") ]]; then echo >&2 \"I require $@ but it's not executable. Aborting.\"; exit 1; fi } function exitOnFail { \"$@\" local status=$? if [ $status -ne 0 ]; then echo \"$@ failed with $1\" exit $status fi return $status } function run_reqcheck { pushd \"$automizer_folder\" > /dev/null local dump_folder=\"$PWD\"\"/dump-\"`basename $req_file` if ! readlink -e \"$PWD/plugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar\" > /dev/null ; then echo \"$PWD does not contain Ultimate binaries\" exit 1 fi if readlink -e \"$dump_folder\" > /dev/null ; then echo \"Found old dump directory $dump_folder\" if prompt \"Should I delete the directory?\" ; then rm -r \"$dump_folder\" else exit 1 fi fi if readlink -e \"$reqcheck_log\" > /dev/null ; then echo \"Logfile $reqcheck_log already exists\" if prompt \"Overwrite?\" ; then rm \"$reqcheck_log\" else exit 1 fi fi echo \"Analyzing $req_file\" echo \"Using log file $reqcheck_log\" mkdir \"$dump_folder\" java \\ -Dosgi.configuration.area=config/ \\ -Xmx100G \\ -Xss4m \\ -jar plugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar \\ -tc \"$reqcheck_toolchain\" \\ -s \"$reqcheck_settings\" \\ -i \"$req_file\" \\ --core.print.statistic.results false \\ --traceabstraction.dump.smt.script.to.file true \\ --traceabstraction.to.the.following.directory=\"$dump_folder\" \\ --traceabstraction.limit.analysis.time $timeout_per_assertion \\ --pea2boogie.always.use.all.invariants.during.rt-inconsistency.checks true \\ --pea2boogie.check.vacuity true \\ --pea2boogie.check.consistency true \\ --pea2boogie.check.rt-inconsistency true \\ --pea2boogie.report.trivial.rt-consistency false \\ --pea2boogie.rt-inconsistency.range $rt_inconsistency_range \\ > \"$reqcheck_log\" popd > /dev/null ### Postprocess results with vacuity extractor if [ ! -f \"$reqcheck_log\" ]; then echo \"File $reqcheck_log was not created; aborting.\" exit 1 fi echo \"Extracting results to $reqcheck_relevant_log\" grep \" -\" \"$reqcheck_log\" | grep -v \"StatisticsResult\" | grep -v \"ReqCheckSuccessResult\" \\ > \"$reqcheck_relevant_log\" if grep -q \"vacuous\" \"$reqcheck_relevant_log\" ; then echo \"Analyzing reasons for vacuity\" pushd \"$dump_folder\" > /dev/null exitOnFail ${vac_extractor} \"$req_file\" \"$reqcheck_log\" mv *.vac.req \"$log_folder\"\"/\" popd > /dev/null else echo \"No vacuities found\" fi } function run_testgen { echo \"Using log file $testgen_log\" pushd \"${automizer_folder}\" > /dev/null if ! readlink -e \"$PWD/plugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar\" > /dev/null ; then echo \"$PWD does not contain Ultimate binaries\" exit 1 fi java \\ -Dosgi.configuration.area=config/ \\ -Xmx100G \\ -Xss4m \\ -jar plugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar \\ -tc \"$testgen_toolchain\" \\ -s \"$testgen_settings\" \\ -i \"$req_file\" \\ --core.print.statistic.results false \\ --rcfgbuilder.simplify.code.blocks false \\ --rcfgbuilder.size.of.a.code.block LoopFreeBlock \\ --traceabstraction.limit.analysis.time $timeout_per_assertion \\ --rcfgbuilder.add.additional.assume.for.each.assert false \\ > \"$testgen_log\" sed -ne '/--- Results ---/,$p' \"$testgen_log\" > \"$testgen_relevant_log\" popd > /dev/null } ### Check parameters for i in \"$ultimate_repo_folder\" \"$automizer_folder\" \"$req_folder\" ; do if [ ! -d \"$i\" ]; then echo \"Folder $i does not exist\" exit 1 fi done for i in \"$req_file\" \"$reqcheck_toolchain\" \"$reqcheck_settings\" \"$testgen_toolchain\" \"$testgen_settings\" ; do if [ ! -f \"$i\" ]; then echo \"File $i does not exist\" exit 1 fi done test_if_cmd_is_available ${vac_extractor} req_file=`readlink -f \"$req_file\"` reqcheck_log=\"$req_folder\"\"/\"`basename $req_file`\".log\" testgen_log=\"$req_folder\"\"/\"`basename $req_file`\".testgen.log\" req_file_name=$(basename -- \"$req_file\") req_file_name=\"${req_file_name%.*}\" log_folder=\"$req_folder\"\"/logs/\"\"$req_file_name\" reqcheck_relevant_log=\"$log_folder\"\"/\"\"$req_file_name\"\".req.relevant.log\" testgen_relevant_log=\"$log_folder\"\"/\"\"$req_file_name\"\".req.testgen.log\" ### Prepare folders if [ ! -d \"$log_folder\" ]; then if prompt \"$log_folder does not exist, should I create it?\" ; then mkdir -p \"$log_folder\" else exit 2 fi fi ### Start running actual tools echo \"Running ReqChecker\" exitOnFail run_reqcheck echo \"Running TestGen\" exitOnFail run_testgen ### Print result summary cat<<EOF Results for $1 Test-cases: $testgen_relevant_log ReqChecker results: $reqcheck_relevant_log Reasons for vacuity: `grep -q \"vacuous\" \"$reqcheck_relevant_log\" && ls ${log_folder}/*.vac.req` Full ReqCheck logfile $reqcheck_log Full TestGen logfile $testgen_log EOF exit 0 Use Ultimate # We now simply execute the run_complete_analysis.sh script. $ cd hanfor/example $ ./run_complete_analysis.sh example_input.req This will fire up Ultimate and run an analysis. The analysis checks for rt-inconsistency and vacuity and logs are be generated: hanfor/example/example_input.req.log hanfor/example/example_input.req.testgen.log hanfor/example/logs/example_input/example_input.req.relevant.log hanfor/example/logs/example_input/example_input.req.testgen.log Evaluate # In hanfor/example/example_input.req.log we can see that Ultimate reports: --- Results --- * Results from de.uni_freiburg.informatik.ultimate.pea2boogie: - RequirementInconsistentErrorResult: Requirements set is inconsistent. Requirements set is inconsistent. Some invariants are already infeasible. Responsible requirements: REQ6_0, REQ3_0, REQ4_0 Now, if we investigate REQ3, REQ4 and REQ6: REQ3_0: Globally, it is always the case that \"constraint1\" holds REQ4_0: Globally, it is always the case that \"constraint2\" holds REQ6_0: Globally, it is never the case that \"constraint1 && constraint2 \" holds We directly see what the problem is: On one hand, our invariants demand that constraint1 and constraint2 always holds, but on the other hand there is another invariant which demands that constraint1 and constraint2 never hold at the same time. Think about this as: constraint1 && constraint2 && ((constraint1 && !constraint2) || (!constraint1 && constraint2)) this is clearly unsatisfiable. Alter your requirements # We now found an inconsistency in our requirements, that has to be fixed. Let's assume you review your requirements and you recognize REQ4 was defined wrong in the csv, where REQ4,constraint2 always holds,requirement should be REQ4,constraint2 never holds,requirement . While reading over the requirements, you also recognize that REQ1 and REQ5 collide and you find out that REQ5 shall be deleted. When we apply this changes, we end up with the following changes: alter REQ4,constraint2 always holds,requirement to REQ4,constraint2 never holds,requirement remove REQ5 and our csv file now looks as follows: ID,Description,Type META1,This is an example for some requirements,meta META2,Next we define some requirements,meta REQ1,var1 is always greater than 5,requirement REQ2,var2 is always smaller than 10,requirement REQ3,constraint1 always holds,requirement REQ4,constraint2 never holds,requirement REQ6,constraint1 and constraint2 never hold at the same time,requirement REQ7,if var1 = True then var3 = 0,requirement REQ8,if var1 = True then var3 = 1,requirement Time for a new revision. # We altered our requirements, we now need to create a new revision in Hanfor and change our formalizations. Execute: $ cd hanfor $ python3 app.py -r -c example/example_input.csv example_tag Hanfor will then ask: \"Which revision should I use as a base?\" , we choose revision_0 (as it is the only one, usually you want your latest revision). Then, Hanfor asks Should I use the csv header mapping from base revision? , as we did not change the csv header, we just keep the current one. A quick recap what happens when creating a revision: - New requirements get the tag revision_0_to_revision_1_new_requirement - Changed requirements get the tag revision_0_to_revision_1_data_changed and revision_0_to_revision_1_description_changed - Requirements where the formalization migrated to the new revision get the tag revision_0_to_revision_1_migrated_formalized We now have to alter the requirements which have changed, that's only REQ4 . Open the formalization of REQ4 and correct it to Globally, it is never the case that \"constraint2\" holds . Ultimate Analysis #2 # Export your requirements as before with the name example_input_revision1.req Run Ultimate on the new requirements file. You can now examine the log created in hanfor/example/logs/example_input/example_input.req.relevant.log , which contains the following: - ReqCheckFailResult [Line: -1]: Requirements REQ8_0, REQ7_0 are rt-inconsistent A ReqCheckFailResult usually implies that something is broken, Ultimate found that requirements REQ7 and REQ8 are rt-inconsistent, let's analyze this result: REQ7,if var1 = True then var3 = 0,requirement REQ8,if var1 = True then var3 = 1,requirement These two requirements collide, because they assign different values to var3 when var1 holds. This is especially bad in a realtime system, because it can happen that var3 == 0 holds after a certain amount of time, and var3 == 1 holds at a later point of time or vice versa. Why is this bad? - because it can cause unexpected behaviour when a change propagates through the system. Conclusion # You are now able to: Setup hanfor, Formalize requirements, Filter requirements, Export them to a .req file Run Ultimate on a .req file Interpret the results of Ultimate Create new revisions in hanfor to fix mistakes in requirements.","title":"Workflow"},{"location":"usage/workflow/#workflow","text":"This example and everything that belongs to it is located in hanfor/example .","title":"Workflow"},{"location":"usage/workflow/#example-input","text":"Consider a CSV file example_input.csv which contains requirements: ID,Description,Type META1,This is an example for some requirements,meta META2,Next we define some requirements,meta REQ1,var1 is always greater than 5,requirement REQ2,var2 is always smaller than 10,requirement REQ3,constraint1 always holds,requirement REQ4,constraint2 always holds,requirement REQ5,var1 is always smaller than 5,requirement REQ6,constraint1 and constraint2 never hold at the same time,requirement REQ7,if var1 = True then var3 := 1,requirement REQ8,if var1 = True then var3 := 0,requirement In this case every row consists of the fields ID , Description , Formalized Requirement and Type . ID is a unique identifier, Description is the description , Formalized Requirement , is the formalization, Type , is a type, in this example meta or requirement , where rows with type meta contain some meta-information and rows with type requirement contain actual requirements of the module you want to formalize.","title":"Example input"},{"location":"usage/workflow/#fire-up-hanfor","text":"Configure Hanfor as explained in Configuration Start Hanfor: cd hanfor python3 app.py -c example_input.csv example_tag -c example_input.csv specifies the csv input file we pass. example_tag is some meaningful tag you want to give this session. If you start hanfor later with the same tag, you'll start exactly this session. you can now reach Hanfor by visiting http://127.0.0.1:5000 Hanfor requirement overview","title":"Fire up Hanfor"},{"location":"usage/workflow/#preprocessing","text":"By default, all rows now have the status Todo . It might be the case that you want to change this for a certain set of rows to another status. In this example we want to set every row of type meta to the status Done . To accomplish this we use the Search Query Language . In Hanfor, search :COL_INDEX_04:meta . This will search for rows which match \"meta\" in the 4. coloumn (Type). You should now only see the rows of type meta . Select all rows by clicking All . Click Edit selected and select Done in the field Set status . Finally, click Apply changes to selected requirements","title":"Preprocessing"},{"location":"usage/workflow/#formalization","text":"Order your requirement overview by Pos by clicking on the table column.","title":"Formalization"},{"location":"usage/workflow/#req1","text":"To formalize this requirement, we click on the ID REQ1 to open then formalization-modal: Formalization modal Click on + to add a new formalization and then on ..(click to open) We now have to select a Scope and a Pattern . - The scope is Globally , because the requirement states that \"var1 is always greater than 5\". - The pattern is it is always the case that {R} holds . - For {R} we insert the condition: var1 > 5 - Set the status to Review and then press save changes . If you save a requirement, Hanfor will automatically create the used variables and derive their type. You can examine and even alter them in the section Variables , for the case that Hanfor did not derive a variable-type correctly. Definition of Scope and Pattern The same procedure can be applied to REQ2 - REQ6","title":"REQ1"},{"location":"usage/workflow/#req7-and-req8","text":"REQ7 and REQ8 are different. Consider REQ7: if var3 = True then var4 := True . The scope is still Globally The pattern is it is always the case that if \"{R}\" holds, then \"{S}\" holds after at most \"{T}\" time units , because in a realtime-system a variable assignment does not happen instantly, there can be delays. For {R} we insert var3 , because the variable type is boolean. For {S} insert var4 , For {T} we need a certain amount of time units, for example 50. We do not want to hardcode values, we introduce a new variable and insert MAX_TIME . We end up with the following: Globally, it is always the case that if \"var3\" holds, then \"var4\" holds after at most \"MAX_TIME\" time units. Save the formalization. You will now recognize that Hanfor automatically added a new Tag Type_inference_error to your freshly formalized requirement. To fix that, to go the Variables section and open the MAX_TIME variable. You see that Hanfor derived the type bool , but we actually want it to be of type CONST as the variable represents time units. Change the type and also assign a value, for example 50 . Example for the MAX_TIME variable For REQ8 you should have: Globally, it is always the case that if \"var3\" holds, then \"!var4\" holds after at most \"MAX_TIME\" time units.","title":"REQ7 and REQ8"},{"location":"usage/workflow/#exporting-the-formalized-requirements","text":"Once you are done with all requirements, it is time to analyze them using a tool like Ultimate (TODO:ref to git).","title":"Exporting the formalized requirements."},{"location":"usage/workflow/#preparing-the-export","text":"You might want to filter out some rows, for example, all of type meta or all that have a certain tag. Again, use the Search Query Language to select only the requirements you want. For example, if we only rows of type requirement which are not on status Todo we search: :COL_INDEX_04:requirement:AND::COL_INDEX_06::NOT:Todo","title":"Preparing the export."},{"location":"usage/workflow/#export","text":"To export requirements, press Tools , then choose either .req or .csv . If you want to analyze the requirements using Ultimate, choose Generate .req file from (filtered) requirements table and then save it. You should end up with the following: CONST MAX_TIME IS 50.0 Input constraint1 IS bool Input constraint2 IS bool Input var1 IS int Input var2 IS int Input var3 IS bool Input var4 IS bool REQ1_0: Globally, it is always the case that \"var1 > 5\" holds REQ2_0: Globally, it is always the case that \"var2 < 10\" holds REQ3_0: Globally, it is always the case that \"constraint1\" holds REQ4_0: Globally, it is always the case that \"constraint2\" holds REQ5_0: Globally, it is always the case that \"var1 < 5\" holds REQ6_0: Globally, it is never the case that \"constraint1 && constraint2 \" holds REQ7_0: Globally, it is always the case that if \"var3\" holds, then \"var4\" holds after at most \"MAX_TIME\" time units REQ8_0: Globally, it is always the case that if \"var3\" holds, then \"!var4\" holds after at most \"MAX_TIME \" time units","title":"Export"},{"location":"usage/workflow/#analysis-using-ultimate","text":"","title":"Analysis using Ultimate."},{"location":"usage/workflow/#get-ultimate","text":"First of all you need Ultimate Install Java JDK (1.8) and Maven (>3.0) Clone the repository: git clone https://github.com/ultimate-pa/ultimate . Navigate to the release scripts cd ultimate/releaseScripts/default/ Generate a fresh binary ./makeFresh.sh You have now successfully forged binaries, which are located in UAutomizer-linux/ .","title":"Get Ultimate"},{"location":"usage/workflow/#scripts-to-perform-the-complete-analysis","text":"We wrote scripts, which perform a complete anaylsis, including the extraction of relevant stuff. Just copy the following three scripts, and change the directories in the head of the files where it is necessary. explode_script.py : #!/usr/bin/env python3 import argparse import re import sys def get_top_operands(s): operands = [] pstack = [] last_space = None for i, c in enumerate(s): if c == '(': pstack.append(i) elif c == ')': if len(pstack) == 0: print(s) raise IndexError(\"No matching closing parens at: \" + str(i)) j = pstack.pop() last_space = None if len(pstack) == 0: operands.append(s[j:i + 1]) elif c == ' ': if not last_space: last_space = i else: if len(pstack) == 0: # we have a top level operand without parenthesis operands.append(s[last_space:i + 1]) last_space = i if len(pstack) > 0: print(s) raise IndexError(\"No matching opening parens at: \" + str(pstack.pop())) return operands def split_and(s): if s.startswith('(and'): rtr = [] for operand in get_top_operands(s[5:len(s) - 1]): rtr = rtr + split_and(operand) return rtr else: return [s] parser = argparse.ArgumentParser(description='Convert (assert (and o1 o2 ...)) to (assert o1) (assert o2) (assert ...)') parser.add_argument('-i', '--input', nargs=1, metavar='<file>', required=True, help='Specify input file') parser.add_argument('-o', '--output', nargs=1, metavar='<file>', required=True, help='Specify output file') try: args, extras = parser.parse_known_args() except argparse.ArgumentError as exc: print(exc.message + '\\n' + exc.argument) sys.exit(1) input_script = args.input[0] output_script = args.output[0] if input_script == output_script: print('Input and output file must be different') sys.exit(1) try: with open(input_script, encoding='utf-8') as f, open(output_script, 'w', encoding='utf-8') as o: for line in f.readlines(): if line.startswith(\"(assert (!\"): m = re.search('\\(assert \\(! (.*?) :named (.*?)\\)\\)', line) formula = m.group(1) if formula == 'true': continue name = m.group(2) asserts = split_and(formula) if len(asserts) == 1: o.write('(assert (! {} :named {}))\\n'.format(asserts[0], name)) else: i = 0 for sub in asserts: o.write('(assert (! {} :named {}))\\n'.format(sub, name + '_' + str(i))) i = i + 1 else: o.write(line) except FileNotFoundError as exc: print('Did not find ' + input_script) print('Arguments were '+ str(args)) sys.exit(1) extract_vac_reasons.sh , used to extract reasons why a requirement is vacuous. #!/bin/bash # script that prepares a .req file with the reasons for vacuity for a known vacuous requirement # start it from the initial dump directory orig_req_file=\"${1}\" ultimate_log=\"${2}\" # This is what you have to change: requirement_repo=\"/storage/repos/your_requirement_repo\" ultimate_repo=\"/storage/repos/ultimate\" explode=\"${requirement_repo}/explode_script.py\" ultimate_dir=\"${ultimate_repo}/releaseScripts/default/UAutomizer-linux\" # Below here you do not have to change anything, except you know what you are doing. tmp_dump_dir=\"dump-ss\" dump_dir=\"dump\" function check_params(){ if [[ $PWD != *\"$dump_dir\" ]]; then echo \"Not in directory $dump_dir\" exit 1; fi } function parse_results(){ mapfile -t results < <( grep -oP ' - .*Result.*' \"$ultimate_log\" | grep 'is vacuous' | grep -oP 'Requirement .* is' | cut -d ' ' -f 2 ) } function print_results(){ if [ ${#results[@]} -eq 0 ]; then echo \"No vacuous requirements remaining! This is unexpected. Check $reduced_req_file and $ultimate_log\" return 1 else echo \"${#results[@]} requirements still vacuous: ${results[@]}\" return 0 fi } function get_involved_reqs(){ local reason_file=\"$req_id.vac\" local tmp_file=\"$req_id.tmp\" local regexpr=\"\" if readlink -e \"$tmp_file\" > /dev/null ; then echo \"$tmp_file still exists\" exit 1 fi for smt_file in $smt_file_pref do echo \"Considering $smt_file\" tmp_smt_file=\"${smt_file}.lbe\" eval \"$explode -i $smt_file -o $tmp_smt_file\" if ! readlink -e \"$tmp_smt_file\" > /dev/null ; then echo \"$explode -i $smt_file -o $tmp_smt_file did not produce the expected output, something is wrong\" echo \"The current folder is $PWD\" exit 1 fi sed -i 's/(get-interpolants.*/(get-unsat-core)/g' \"$tmp_smt_file\" sed -i '/\\:interpolant-check-mode/d' \"$tmp_smt_file\" sed -i '/\\:proof-transformation/d' \"$tmp_smt_file\" sed -i '/\\:array-interpolation/d' \"$tmp_smt_file\" # You can check if z3 complains about something in the file #../z3 \"$tmp_smt_file\" for i in `\"$ultimate_dir/z3\" \"$tmp_smt_file\" | grep -A 1 -P ^unsat$ | tail -n +2 | sed 's/(//g' | sed 's/)//g'`; do grep \"$i\" \"$tmp_smt_file\"; done | grep -oP 'SysRS_\\w+_\\d+_\\d+' | sort | uniq >> \"$tmp_file\" rm \"$tmp_smt_file\" done sort \"$tmp_file\" | uniq > \"$reason_file\" rm \"$tmp_file\" if ! grep -q \"$req_id\" \"$reason_file\" ; then echo \"TODO: if the tmp_file does not contain the req_id in the unsat core, we need to remove reasons for infeasibility and try again\" return 1 fi echo \"Found `wc -l $reason_file | cut -d \" \" -f 1` involved reqs\" tr '[:space:]' ' ' < \"$reason_file\" echo \"\" for i in `cat $reason_file` ; do regexpr+=\"\\|$i.*$\"; done rm \"$reason_file\" sed \"/CONST.*$\\|Input.*$\"\"$regexpr/!d\" \"$orig_req_file\" > \"$reduced_req_file\" return 0 } function run_ultimate_ss(){ rm -r \"$tmp_dump_dir\" mkdir \"$tmp_dump_dir\" ultimate_log=`readlink -f \"${tmp_dump_dir}/ultimate.log\"` echo \"Running Ultimate\" java -Dosgi.configuration.area=config/ \\ -Xmx10G \\ -jar plugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar \\ -tc \"${ultimate_repo}/trunk/examples/toolchains/ReqCheck.xml\" \\ -s \"${requirement_repo}/reqanalyzer-nonlin.epf\" \\ -i \"${dump_dir}/$reduced_req_file\" \\ --pea2boogie.check.consistency false \\ --pea2boogie.check.rt-inconsistency false \\ --traceabstraction.dump.smt.script.to.file true \\ --traceabstraction.to.the.following.directory=\"${tmp_dump_dir}/\" \\ > \"$ultimate_log\" } check_params parse_results initial_results=\"${results[@]}\" echo \"Processing ${#results[@]} vacuous requirements\" for i in ${initial_results[@]} do req_id=\"$i\" reduced_req_file=\"$req_id.vac.req\" echo \"----\" echo \"Processing $req_id\" smt_file_pref=\"*VAC*_\"`echo \"$req_id\" | cut -d \"_\" -f 3-`\"_*.smt2\" if ! get_involved_reqs ; then continue fi pushd \"$ultimate_dir\" > /dev/null run_ultimate_ss parse_results if print_results ; then pushd \"$tmp_dump_dir\" > /dev/null get_involved_reqs echo \"Writing $reduced_req_file\" cp \"$reduced_req_file\" \"../${dump_dir}/\" cp \"$reduced_req_file\" \"../\" popd > /dev/null fi popd > /dev/null echo \"Finished $req_id\" echo \"\" done run_complete_analysis.sh , used to run the complete analysis. #!/bin/bash # script that runs all the various requirement analysis scripts and moves files around in the matching directories ### Default settings # The requirement file is an argument passed to this script. req_file=\"$1\" # This is the path to the repository, which contains the requirements-folder req_repo_folder=\"/path/to/req/repo\" # This is the path to the requirements-folder req_folder=\"${req_repo_folder}/reqs\" # Path to the vacuity extractor script. vac_extractor=\"${req_repo_folder}/extract_vac_reasons.sh\" # Path to the Ultimate repository. ultimate_repo_folder=\"/storage/repos/ultimate\" # Path to Ultimate Automizer (remember those binaries we created earlier? that's what you want!). automizer_folder=\"${ultimate_repo_folder}/releaseScripts/default/UAutomizer-linux\" # Don't touch this, unless you know what you are doing. reqcheck_toolchain=\"${ultimate_repo_folder}/trunk/examples/toolchains/ReqCheck.xml\" reqcheck_settings=\"${ultimate_repo_folder}/trunk/examples/settings/reqanalyzer/reqanalyzer-nonlin.epf\" testgen_toolchain=\"${ultimate_repo_folder}/trunk/examples/toolchains/ReqToTest.xml\" testgen_settings=\"${ultimate_repo_folder}/trunk/examples/settings/ReqToTest.epf\" # The time how long a single assertion is checked. timeout_per_assertion=900 # The amount of requirements which are checked together for RT-inconsistency. # Careful with this parameter, it will blow up the amount of checks really fast. rt_inconsistency_range=2 ### Functions function prompt { read -p \"${1} [y/N]\" -n 1 -r echo \"\" if [[ $REPLY =~ ^[Yy]$ ]] ; then return 0 fi return 1 } function test_if_cmd_is_available { local cmd_path=`command -v \"$@\"` [ $? -eq 0 ] || { echo >&2 \"I require $@ but it's not installed. Aborting.\"; exit 1; } if ! [[ -f \"$cmd_path\" && -x $(realpath \"$cmd_path\") ]]; then echo >&2 \"I require $@ but it's not executable. Aborting.\"; exit 1; fi } function exitOnFail { \"$@\" local status=$? if [ $status -ne 0 ]; then echo \"$@ failed with $1\" exit $status fi return $status } function run_reqcheck { pushd \"$automizer_folder\" > /dev/null local dump_folder=\"$PWD\"\"/dump-\"`basename $req_file` if ! readlink -e \"$PWD/plugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar\" > /dev/null ; then echo \"$PWD does not contain Ultimate binaries\" exit 1 fi if readlink -e \"$dump_folder\" > /dev/null ; then echo \"Found old dump directory $dump_folder\" if prompt \"Should I delete the directory?\" ; then rm -r \"$dump_folder\" else exit 1 fi fi if readlink -e \"$reqcheck_log\" > /dev/null ; then echo \"Logfile $reqcheck_log already exists\" if prompt \"Overwrite?\" ; then rm \"$reqcheck_log\" else exit 1 fi fi echo \"Analyzing $req_file\" echo \"Using log file $reqcheck_log\" mkdir \"$dump_folder\" java \\ -Dosgi.configuration.area=config/ \\ -Xmx100G \\ -Xss4m \\ -jar plugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar \\ -tc \"$reqcheck_toolchain\" \\ -s \"$reqcheck_settings\" \\ -i \"$req_file\" \\ --core.print.statistic.results false \\ --traceabstraction.dump.smt.script.to.file true \\ --traceabstraction.to.the.following.directory=\"$dump_folder\" \\ --traceabstraction.limit.analysis.time $timeout_per_assertion \\ --pea2boogie.always.use.all.invariants.during.rt-inconsistency.checks true \\ --pea2boogie.check.vacuity true \\ --pea2boogie.check.consistency true \\ --pea2boogie.check.rt-inconsistency true \\ --pea2boogie.report.trivial.rt-consistency false \\ --pea2boogie.rt-inconsistency.range $rt_inconsistency_range \\ > \"$reqcheck_log\" popd > /dev/null ### Postprocess results with vacuity extractor if [ ! -f \"$reqcheck_log\" ]; then echo \"File $reqcheck_log was not created; aborting.\" exit 1 fi echo \"Extracting results to $reqcheck_relevant_log\" grep \" -\" \"$reqcheck_log\" | grep -v \"StatisticsResult\" | grep -v \"ReqCheckSuccessResult\" \\ > \"$reqcheck_relevant_log\" if grep -q \"vacuous\" \"$reqcheck_relevant_log\" ; then echo \"Analyzing reasons for vacuity\" pushd \"$dump_folder\" > /dev/null exitOnFail ${vac_extractor} \"$req_file\" \"$reqcheck_log\" mv *.vac.req \"$log_folder\"\"/\" popd > /dev/null else echo \"No vacuities found\" fi } function run_testgen { echo \"Using log file $testgen_log\" pushd \"${automizer_folder}\" > /dev/null if ! readlink -e \"$PWD/plugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar\" > /dev/null ; then echo \"$PWD does not contain Ultimate binaries\" exit 1 fi java \\ -Dosgi.configuration.area=config/ \\ -Xmx100G \\ -Xss4m \\ -jar plugins/org.eclipse.equinox.launcher_1.3.100.v20150511-1540.jar \\ -tc \"$testgen_toolchain\" \\ -s \"$testgen_settings\" \\ -i \"$req_file\" \\ --core.print.statistic.results false \\ --rcfgbuilder.simplify.code.blocks false \\ --rcfgbuilder.size.of.a.code.block LoopFreeBlock \\ --traceabstraction.limit.analysis.time $timeout_per_assertion \\ --rcfgbuilder.add.additional.assume.for.each.assert false \\ > \"$testgen_log\" sed -ne '/--- Results ---/,$p' \"$testgen_log\" > \"$testgen_relevant_log\" popd > /dev/null } ### Check parameters for i in \"$ultimate_repo_folder\" \"$automizer_folder\" \"$req_folder\" ; do if [ ! -d \"$i\" ]; then echo \"Folder $i does not exist\" exit 1 fi done for i in \"$req_file\" \"$reqcheck_toolchain\" \"$reqcheck_settings\" \"$testgen_toolchain\" \"$testgen_settings\" ; do if [ ! -f \"$i\" ]; then echo \"File $i does not exist\" exit 1 fi done test_if_cmd_is_available ${vac_extractor} req_file=`readlink -f \"$req_file\"` reqcheck_log=\"$req_folder\"\"/\"`basename $req_file`\".log\" testgen_log=\"$req_folder\"\"/\"`basename $req_file`\".testgen.log\" req_file_name=$(basename -- \"$req_file\") req_file_name=\"${req_file_name%.*}\" log_folder=\"$req_folder\"\"/logs/\"\"$req_file_name\" reqcheck_relevant_log=\"$log_folder\"\"/\"\"$req_file_name\"\".req.relevant.log\" testgen_relevant_log=\"$log_folder\"\"/\"\"$req_file_name\"\".req.testgen.log\" ### Prepare folders if [ ! -d \"$log_folder\" ]; then if prompt \"$log_folder does not exist, should I create it?\" ; then mkdir -p \"$log_folder\" else exit 2 fi fi ### Start running actual tools echo \"Running ReqChecker\" exitOnFail run_reqcheck echo \"Running TestGen\" exitOnFail run_testgen ### Print result summary cat<<EOF Results for $1 Test-cases: $testgen_relevant_log ReqChecker results: $reqcheck_relevant_log Reasons for vacuity: `grep -q \"vacuous\" \"$reqcheck_relevant_log\" && ls ${log_folder}/*.vac.req` Full ReqCheck logfile $reqcheck_log Full TestGen logfile $testgen_log EOF exit 0","title":"Scripts to perform the complete analysis."},{"location":"usage/workflow/#use-ultimate","text":"We now simply execute the run_complete_analysis.sh script. $ cd hanfor/example $ ./run_complete_analysis.sh example_input.req This will fire up Ultimate and run an analysis. The analysis checks for rt-inconsistency and vacuity and logs are be generated: hanfor/example/example_input.req.log hanfor/example/example_input.req.testgen.log hanfor/example/logs/example_input/example_input.req.relevant.log hanfor/example/logs/example_input/example_input.req.testgen.log","title":"Use Ultimate"},{"location":"usage/workflow/#evaluate","text":"In hanfor/example/example_input.req.log we can see that Ultimate reports: --- Results --- * Results from de.uni_freiburg.informatik.ultimate.pea2boogie: - RequirementInconsistentErrorResult: Requirements set is inconsistent. Requirements set is inconsistent. Some invariants are already infeasible. Responsible requirements: REQ6_0, REQ3_0, REQ4_0 Now, if we investigate REQ3, REQ4 and REQ6: REQ3_0: Globally, it is always the case that \"constraint1\" holds REQ4_0: Globally, it is always the case that \"constraint2\" holds REQ6_0: Globally, it is never the case that \"constraint1 && constraint2 \" holds We directly see what the problem is: On one hand, our invariants demand that constraint1 and constraint2 always holds, but on the other hand there is another invariant which demands that constraint1 and constraint2 never hold at the same time. Think about this as: constraint1 && constraint2 && ((constraint1 && !constraint2) || (!constraint1 && constraint2)) this is clearly unsatisfiable.","title":"Evaluate"},{"location":"usage/workflow/#alter-your-requirements","text":"We now found an inconsistency in our requirements, that has to be fixed. Let's assume you review your requirements and you recognize REQ4 was defined wrong in the csv, where REQ4,constraint2 always holds,requirement should be REQ4,constraint2 never holds,requirement . While reading over the requirements, you also recognize that REQ1 and REQ5 collide and you find out that REQ5 shall be deleted. When we apply this changes, we end up with the following changes: alter REQ4,constraint2 always holds,requirement to REQ4,constraint2 never holds,requirement remove REQ5 and our csv file now looks as follows: ID,Description,Type META1,This is an example for some requirements,meta META2,Next we define some requirements,meta REQ1,var1 is always greater than 5,requirement REQ2,var2 is always smaller than 10,requirement REQ3,constraint1 always holds,requirement REQ4,constraint2 never holds,requirement REQ6,constraint1 and constraint2 never hold at the same time,requirement REQ7,if var1 = True then var3 = 0,requirement REQ8,if var1 = True then var3 = 1,requirement","title":"Alter your requirements"},{"location":"usage/workflow/#time-for-a-new-revision","text":"We altered our requirements, we now need to create a new revision in Hanfor and change our formalizations. Execute: $ cd hanfor $ python3 app.py -r -c example/example_input.csv example_tag Hanfor will then ask: \"Which revision should I use as a base?\" , we choose revision_0 (as it is the only one, usually you want your latest revision). Then, Hanfor asks Should I use the csv header mapping from base revision? , as we did not change the csv header, we just keep the current one. A quick recap what happens when creating a revision: - New requirements get the tag revision_0_to_revision_1_new_requirement - Changed requirements get the tag revision_0_to_revision_1_data_changed and revision_0_to_revision_1_description_changed - Requirements where the formalization migrated to the new revision get the tag revision_0_to_revision_1_migrated_formalized We now have to alter the requirements which have changed, that's only REQ4 . Open the formalization of REQ4 and correct it to Globally, it is never the case that \"constraint2\" holds .","title":"Time for a new revision."},{"location":"usage/workflow/#ultimate-analysis-2","text":"Export your requirements as before with the name example_input_revision1.req Run Ultimate on the new requirements file. You can now examine the log created in hanfor/example/logs/example_input/example_input.req.relevant.log , which contains the following: - ReqCheckFailResult [Line: -1]: Requirements REQ8_0, REQ7_0 are rt-inconsistent A ReqCheckFailResult usually implies that something is broken, Ultimate found that requirements REQ7 and REQ8 are rt-inconsistent, let's analyze this result: REQ7,if var1 = True then var3 = 0,requirement REQ8,if var1 = True then var3 = 1,requirement These two requirements collide, because they assign different values to var3 when var1 holds. This is especially bad in a realtime system, because it can happen that var3 == 0 holds after a certain amount of time, and var3 == 1 holds at a later point of time or vice versa. Why is this bad? - because it can cause unexpected behaviour when a change propagates through the system.","title":"Ultimate Analysis #2"},{"location":"usage/workflow/#conclusion","text":"You are now able to: Setup hanfor, Formalize requirements, Filter requirements, Export them to a .req file Run Ultimate on a .req file Interpret the results of Ultimate Create new revisions in hanfor to fix mistakes in requirements.","title":"Conclusion"}]}